{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/data/theory/robustopt/aajay/models/Places_room_adv.pt'\n",
      "=> loaded checkpoint '/data/theory/robustopt/aajay/models/Places_room_adv.pt' (epoch 105)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['NOTEBOOK_MODE'] = '1'\n",
    "import sys\n",
    "import torch as ch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from scipy import stats\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from robustness import model_utils, datasets\n",
    "from robustness.tools.vis_tools import show_image_row, show_image_column\n",
    "from robustness.tools.constants import CLASS_DICT\n",
    "from pathlib import Path\n",
    "import json\n",
    "sys.path.append('./cycle_gan')\n",
    "from options.test_options import TestOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.visualizer import save_images\n",
    "from util import html, util\n",
    "import argparse\n",
    "%matplotlib inline\n",
    "\n",
    "# Constants\n",
    "CONFIG = 'configs/places_room.json'\n",
    "DATA = 'PlacesRoom' \n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 8\n",
    "NOISE_SCALE = 20\n",
    "\n",
    "DATA_SHAPE = 224 # Image size (fixed for dataset)\n",
    "REPRESENTATION_SIZE = 512 # Size of representation vector (fixed for model)\n",
    "\n",
    "# Load dataset\n",
    "file = open(Path('robustness').joinpath(CONFIG))\n",
    "cfg = json.load(file)\n",
    "file.close()\n",
    "\n",
    "dataset_function = getattr(datasets, DATA)\n",
    "dataset = dataset_function(cfg['data'])\n",
    "\n",
    "# Load Model\n",
    "model_kwargs = {\n",
    "    'arch': 'resnet18',\n",
    "    'dataset': dataset,\n",
    "    'resume_path': '/data/theory/robustopt/aajay/models/Places_room_adv.pt',\n",
    "    'old_format': False,\n",
    "}\n",
    "model_kwargs['state_dict_path'] = 'model'\n",
    "model, _ = model_utils.make_and_restore_model(**model_kwargs)\n",
    "model.eval()\n",
    "\n",
    "# Custom loss to maximize a given component of the representation vector\n",
    "def feature_vis_loss(model, inp, targ):\n",
    "    _, rep = model(inp, \n",
    "                   with_latent=True, \n",
    "                   fake_relu=True) #To propagate gradients through the \"zero-region\" of a ReLU activation\n",
    "    loss = rep[:, targ]\n",
    "    return loss, None\n",
    "\n",
    "# PGD parameters\n",
    "kwargs = {\n",
    "    'criterion': ch.nn.CrossEntropyLoss(),\n",
    "    'custom_loss': feature_vis_loss,\n",
    "    'constraint':'2',\n",
    "    'eps':70,\n",
    "    'step_size': 1,\n",
    "    'iterations': 200, \n",
    "    'use_best': False\n",
    "}\n",
    "\n",
    "Img_choice_to_path = {'study room':'./demo_inputs/study_room.jpg',\n",
    "                      'empty room':'./demo_inputs/living_room.jpg', \n",
    "                      'reading room':'./demo_inputs/reading_room.jpg', \n",
    "                      'hotel room':'./demo_inputs/hotel_room2.jpg',\n",
    "                      'living room':'./demo_inputs/living_room2.jpg',}\n",
    "\n",
    "activation_choice_to_num = {'living room 1':146,\n",
    "                            'living room 2':321,\n",
    "                            'formal room':68,\n",
    "                            'meeting room':296,\n",
    "                            'conference room':338}\n",
    "\n",
    "filter_type = {'sepia':'hotel_cyclegan', 'blue':'hotel2_cyclegan', 'red':'hotel3_cyclegan','green':'hotel4_cyclegan','yellow':'hotel5_cyclegan'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def modify_image(src_img, dst_type, model):\n",
    "    im = ch.tensor(np.transpose(src_img / 255., (0, 3, 1, 2))).float()\n",
    "    act = activation_choice_to_num[dst_type]\n",
    "    _, xadv = model(im.clone(), act, make_adv=True, **kwargs)\n",
    "    return np.transpose(xadv.detach().cpu().numpy(), axes=(0,2,3,1))\n",
    "\n",
    "def add_filter_image(src_img, filter_color):\n",
    "    model_name = filter_type[filter_color]\n",
    "    opt = argparse.Namespace(aspect_ratio=1.0, \n",
    "                             batch_size=1, \n",
    "                             checkpoints_dir='./cycle_gan/checkpoints', \n",
    "                             crop_size=256, dataroot='./cycle_gan/datasets', \n",
    "                             dataset_mode='single', \n",
    "                             direction='AtoB', \n",
    "                             display_id=-1, \n",
    "                             display_winsize=256, \n",
    "                             epoch='latest', \n",
    "                             eval=False, \n",
    "                             gpu_ids=[0], \n",
    "                             init_gain=0.02, \n",
    "                             init_type='normal', \n",
    "                             input_nc=3, \n",
    "                             isTrain=False, \n",
    "                             load_iter=0, \n",
    "                             load_size=256, \n",
    "                             max_dataset_size=float(\"inf\"), \n",
    "                             model='test', \n",
    "                             model_suffix='', \n",
    "                             n_layers_D=3, \n",
    "                             name=model_name, \n",
    "                             ndf=64, \n",
    "                             netD='basic', \n",
    "                             netG='resnet_9blocks', \n",
    "                             ngf=64, \n",
    "                             no_dropout=True, \n",
    "                             no_flip=True, \n",
    "                             norm='instance', \n",
    "                             ntest=float(\"inf\"), \n",
    "                             num_test=50, \n",
    "                             num_threads=0, \n",
    "                             output_nc=3, \n",
    "                             phase='test', \n",
    "                             preprocess='resize_and_crop', \n",
    "                             results_dir='./cycle_gan/sample_results/', \n",
    "                             serial_batches=True, suffix='', \n",
    "                             verbose=False)\n",
    "    filter_model = create_model(opt)\n",
    "    filter_model.setup(opt)         \n",
    "    filter_model.eval()\n",
    "    inp_img = ch.tensor(np.transpose(src_img, axes=(0,3,1,2))).float()\n",
    "    filter_model.set_input({'A':inp_img, 'A_paths':None})\n",
    "    filter_model.test()\n",
    "    visuals = filter_model.get_current_visuals()\n",
    "    visuals = util.tensor2im(visuals['fake_B'])[None]\n",
    "    return visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb490c0ae9045eca163d925dfc175cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Source Image:', options=('study room', 'empty room', 'living room', 'reading room',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df4c6691f814ce8aab87251e2cabba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Destination type:', options=('living room 1', 'living room 2', 'formal room', 'meet…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fd12b0dae24d33bb8229d06c56a707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Color Filter:', options=('sepia', 'blue', 'None'), style=ToggleButtonsStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c763e9398e425cb1c8156669ac6614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Image', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Original Image'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c815d5a16847f5b8dc6ab514cc5e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Final Image'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3188458f13fc4949adf2d5d16b9fe2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import io, sys, os\n",
    "\n",
    "sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "convert_int_scale = lambda arr: ((arr - arr.min()) * (1/(arr.max() - arr.min()) * 255)).astype('uint8')\n",
    "\n",
    "source_image = widgets.ToggleButtons(\n",
    "    options=['study room', 'empty room', 'living room', 'reading room', 'hotel room'],\n",
    "    description='Source Image:',\n",
    "    style=style,\n",
    ") \n",
    "\n",
    "destination_type = widgets.ToggleButtons(\n",
    "    options=['living room 1', 'living room 2', 'formal room', 'meeting room', 'conference room', 'None'],\n",
    "    description='Destination type:',\n",
    "    style=style,\n",
    ")\n",
    "\n",
    "color_filter = widgets.ToggleButtons(\n",
    "    options=['sepia', 'blue', 'red', 'green', 'yellow', 'None'],\n",
    "    description='Color Filter:',\n",
    "    style=style,\n",
    ")\n",
    "\n",
    "source_image_disp = widgets.Image()\n",
    "final_image_disp = widgets.Image()\n",
    "\n",
    "button = widgets.Button(description=\"Generate Image\")\n",
    "\n",
    "@button.on_click\n",
    "def plot_image(b):\n",
    "    img = np.asarray(Image.open(Img_choice_to_path[source_image.value]).resize((224, 224)))[None,:]\n",
    "    if destination_type.value != 'None':\n",
    "        mod_img = modify_image(img, destination_type.value, model)\n",
    "    else:\n",
    "        mod_img = img\n",
    "    if color_filter.value != 'None':\n",
    "        mod_img = add_filter_image(mod_img, color_filter.value)\n",
    "    org_img = Image.fromarray(img[0])\n",
    "    org_img_byte = io.BytesIO()\n",
    "    org_img.save(org_img_byte, format='PNG')\n",
    "    org_img_byte = org_img_byte.getvalue()\n",
    "    fin_img = Image.fromarray(convert_int_scale(mod_img[0]))\n",
    "    fin_img_byte = io.BytesIO()\n",
    "    fin_img.save(fin_img_byte, format='PNG')\n",
    "    fin_img_byte = fin_img_byte.getvalue()\n",
    "    \n",
    "    source_image_disp.value=org_img_byte\n",
    "    final_image_disp.value=fin_img_byte\n",
    "    \n",
    "display(source_image)\n",
    "display(destination_type)\n",
    "display(color_filter)\n",
    "display(button)\n",
    "display(\"Original Image\")\n",
    "display(source_image_disp)\n",
    "display(\"Final Image\")\n",
    "display(final_image_disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
