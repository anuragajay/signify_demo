{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset places_room..\n",
      "=> loading checkpoint '/data/theory/robustopt/aajay/models/Places_room_adv.pt'\n",
      "=> loaded checkpoint '/data/theory/robustopt/aajay/models/Places_room_adv.pt' (epoch 105)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['NOTEBOOK_MODE'] = '1'\n",
    "import sys\n",
    "import torch as ch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from scipy import stats\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from robustness import model_utils, datasets\n",
    "from robustness.tools.vis_tools import show_image_row, show_image_column\n",
    "from robustness.tools.constants import CLASS_DICT\n",
    "from pathlib import Path\n",
    "import json\n",
    "sys.path.append('./cycle_gan')\n",
    "from options.test_options import TestOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.visualizer import save_images\n",
    "from util import html, util\n",
    "import argparse\n",
    "%matplotlib inline\n",
    "\n",
    "# Constants\n",
    "CONFIG = 'configs/places_room.json'\n",
    "DATA = 'PlacesRoom' \n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 8\n",
    "NOISE_SCALE = 20\n",
    "\n",
    "DATA_SHAPE = 224 # Image size (fixed for dataset)\n",
    "REPRESENTATION_SIZE = 512 # Size of representation vector (fixed for model)\n",
    "\n",
    "# Load dataset\n",
    "file = open(Path('robustness').joinpath(CONFIG))\n",
    "cfg = json.load(file)\n",
    "file.close()\n",
    "\n",
    "dataset_function = getattr(datasets, DATA)\n",
    "dataset = dataset_function(cfg['data'])\n",
    "_, test_loader = dataset.make_loaders(workers=NUM_WORKERS, \n",
    "                                      batch_size=BATCH_SIZE // 2, \n",
    "                                      data_aug=False)\n",
    "data_iterator = enumerate(test_loader)\n",
    "\n",
    "# Load Model\n",
    "model_kwargs = {\n",
    "    'arch': 'resnet18',\n",
    "    'dataset': dataset,\n",
    "    'resume_path': '/data/theory/robustopt/aajay/models/Places_room_adv.pt',\n",
    "    'old_format': False,\n",
    "}\n",
    "model_kwargs['state_dict_path'] = 'model'\n",
    "model, _ = model_utils.make_and_restore_model(**model_kwargs)\n",
    "model.eval()\n",
    "\n",
    "# Custom loss to maximize a given component of the representation vector\n",
    "def feature_vis_loss(model, inp, targ):\n",
    "    _, rep = model(inp, \n",
    "                   with_latent=True, \n",
    "                   fake_relu=True) #To propagate gradients through the \"zero-region\" of a ReLU activation\n",
    "    loss = rep[:, targ]\n",
    "    return loss, None\n",
    "\n",
    "# PGD parameters\n",
    "kwargs = {\n",
    "    'criterion': ch.nn.CrossEntropyLoss(),\n",
    "    'custom_loss': feature_vis_loss,\n",
    "    'constraint':'2',\n",
    "    'eps':70,\n",
    "    'step_size': 1,\n",
    "    'iterations': 200, \n",
    "    'use_best': False\n",
    "}\n",
    "\n",
    "Img_choice_to_path = {'study room':'./demo_inputs/study_room.jpg',\n",
    "                      'living room':'./demo_inputs/living_room.jpg', \n",
    "                      'reading room':'./demo_inputs/reading_room.jpg', \n",
    "                      'hotel room':'./demo_inputs/hotel_room2.jpg'}\n",
    "\n",
    "activation_choice_to_num = {'living room 1':146,\n",
    "                            'living room 2':321,\n",
    "                            'formal room':68,\n",
    "                            'meeting room':296,\n",
    "                            'conference room':338}\n",
    "\n",
    "filter_type = {'sepia':'hotel_cyclegan', 'blue':'hotel2_cyclegan'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "\n",
    "def modify_image(src_img, dst_type, model):\n",
    "    im = ch.tensor(np.transpose(src_img / 255., (0, 3, 1, 2))).float()\n",
    "    act = activation_choice_to_num[dst_type]\n",
    "    _, xadv = model(im.clone(), act, make_adv=True, **kwargs)\n",
    "    return np.transpose(xadv.detach().cpu().numpy(), axes=(0,2,3,1))\n",
    "\n",
    "def add_filter_image(src_img, filter_color):\n",
    "    model_name = filter_type[filter_color]\n",
    "    opt = argparse.Namespace(aspect_ratio=1.0, \n",
    "                             batch_size=1, \n",
    "                             checkpoints_dir='./cycle_gan/checkpoints', \n",
    "                             crop_size=256, dataroot='./cycle_gan/datasets', \n",
    "                             dataset_mode='single', \n",
    "                             direction='AtoB', \n",
    "                             display_id=-1, \n",
    "                             display_winsize=256, \n",
    "                             epoch='latest', \n",
    "                             eval=False, \n",
    "                             gpu_ids=[0], \n",
    "                             init_gain=0.02, \n",
    "                             init_type='normal', \n",
    "                             input_nc=3, \n",
    "                             isTrain=False, \n",
    "                             load_iter=0, \n",
    "                             load_size=256, \n",
    "                             max_dataset_size=float(\"inf\"), \n",
    "                             model='test', \n",
    "                             model_suffix='', \n",
    "                             n_layers_D=3, \n",
    "                             name=model_name, \n",
    "                             ndf=64, \n",
    "                             netD='basic', \n",
    "                             netG='resnet_9blocks', \n",
    "                             ngf=64, \n",
    "                             no_dropout=True, \n",
    "                             no_flip=True, \n",
    "                             norm='instance', \n",
    "                             ntest=float(\"inf\"), \n",
    "                             num_test=50, \n",
    "                             num_threads=0, \n",
    "                             output_nc=3, \n",
    "                             phase='test', \n",
    "                             preprocess='resize_and_crop', \n",
    "                             results_dir='./cycle_gan/sample_results/', \n",
    "                             serial_batches=True, suffix='', \n",
    "                             verbose=False)\n",
    "    filter_model = create_model(opt)\n",
    "    filter_model.setup(opt)         \n",
    "    filter_model.eval()\n",
    "    inp_img = ch.tensor(np.transpose(src_img, axes=(0,3,1,2))).float()\n",
    "    filter_model.set_input({'A':inp_img, 'A_paths':None})\n",
    "    filter_model.test()\n",
    "    visuals = filter_model.get_current_visuals()\n",
    "    visuals = util.tensor2im(visuals['fake_B'])[None]\n",
    "    return visuals\n",
    "\n",
    "def plot_image(src_img, dst_type, filter_color):\n",
    "    img = np.asarray(Image.open(Img_choice_to_path[src_img]).resize((224, 224)))[None,:]\n",
    "    mod_img = modify_image(img, dst_type, model)\n",
    "    filter_mod_img = add_filter_image(mod_img, filter_color)\n",
    "    print('Original Image')\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "    print('Modified Image')\n",
    "    plt.imshow(mod_img[0])\n",
    "    plt.show()\n",
    "    print('Modified Image+Filter')\n",
    "    plt.imshow(filter_mod_img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE IMAGE CHOICES: study room, living room, reading room, hotel room\n",
    "# DESTINATION TYPE CHOICES: living room 1, living room 2, formal room, meeting room, conference room\n",
    "\n",
    "plot_image(src_img='reading room', dst_type='living room 2', filter_color='sepia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
